{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I will use input_shape with \"224, 168\"\n",
    "\n",
    "FastSCNN \n",
    " - learning to downsample \n",
    " -> global featrue extractor\n",
    " - feature_fusion (learning to downsample, global featrue extractor)\n",
    " - Classifier (feature_fusion)\n",
    " - Interpolation\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "MODULE LIST \n",
    "\n",
    "- ConvBNReLU          : conv2d BN Relu\n",
    "- DSConv              : depthwise + BN + ReLU + pointwise + BN ReLU\n",
    "- DWConv              : Depthwise + BN + ReLU \n",
    "- Linear BottleNeck   : x -> CONVBNRELU  + DWConv + Pointwise + BN -> y + x\n",
    "- PyramidPooling      : pool = adaptiveAvgPool2D, conv=CONVBNRELU, upsampling=Interpolation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def _ConvBNReLU(x, out_ch, k_size=3, stride=1, padding=\"same\", **kwargs):\n",
    "    # add regularization layers and initializer\n",
    "    x = tf.keras.layers.Conv2D(out_ch, \n",
    "                               k_size, \n",
    "                               stride, \n",
    "                               padding, \n",
    "                               kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x \n",
    "\n",
    "def _DWConv(x, k_size=3, stride=1, padding=\"same\", **kwargs):\n",
    "    x = tf.keras.layers.DepthwiseConv2D(k_size, stride, padding,\n",
    "                                        kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def _DSConv(x, out_ch, stride=1):\n",
    "    x = _DWConv(x, stride=stride)\n",
    "    x = tf.keras.layers.Conv2D(out_ch, \n",
    "                               kernel_size=1,\n",
    "                               kernel_initializer='he_normal')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def linearBottlenect(x, out_ch, t=6, stride=1, **kwargs):\n",
    "    use_shortcut = (stride == 1 and x.shape[-1] == out_ch)\n",
    "    # point-wise\n",
    "    out = _ConvBNReLU(x, x.shape[-1]*t, 1)\n",
    "    # depth-wise\n",
    "    out = _DWConv(out, k_size=3, stride=stride)\n",
    "    out = tf.keras.layers.Conv2D(out_ch, \n",
    "                               kernel_size=1, \n",
    "                               use_bias=False,\n",
    "                               kernel_initializer='he_normal')(out)\n",
    "    out = tf.keras.layers.BatchNormalization()(out)\n",
    "    if use_shortcut:\n",
    "        out = x + out\n",
    "    return out\n",
    "\n",
    "def bilinear_interpolation(x, size):\n",
    "    return tf.compat.v1.image.resize_bilinear(x, size, align_corners=True)\n",
    " \n",
    "def __pyramid_module(x, pool_size, inter_ch, **kwargs):\n",
    "    size = x.shape[-3:-1]\n",
    "    x = tf.keras.layers.AveragePooling2D(pool_size=pool_size)(x)\n",
    "    x = _ConvBNReLU(x, inter_ch, k_size=1)\n",
    "    x = tf.keras.layers.Lambda(lambda z:bilinear_interpolation(z, size))(x)\n",
    "    return x \n",
    "    \n",
    "def pyramidPooling(x, out_ch, **kwargs):\n",
    "    inter_ch = x.shape[-1] // 4\n",
    "    fea1 = __pyramid_module(x, pool_size=1, inter_ch=inter_ch)\n",
    "    fea2 = __pyramid_module(x, pool_size=2, inter_ch=inter_ch)\n",
    "    fea3 = __pyramid_module(x, pool_size=3, inter_ch=inter_ch)\n",
    "    fea6 = __pyramid_module(x, pool_size=4, inter_ch=inter_ch)\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([x, fea1, fea2, fea3, fea6])\n",
    "    x = _ConvBNReLU(x, out_ch, k_size=1)\n",
    "    return x\n",
    "    \n",
    "def learningToDownsample(x, dw_ch1=32, dw_ch2=48, out_ch=64, **kwargs):\n",
    "    x = _ConvBNReLU(x, dw_ch1, k_size=3, stride=2)\n",
    "    x = _DSConv(x, dw_ch2, stride=2)\n",
    "    x = _DSConv(x, out_ch, stride=2)\n",
    "    return x\n",
    "\n",
    "def _block_layer(x, block, out_ch, num_block, t=6, stride=1):\n",
    "    x = block(x, out_ch, t=6, stride=stride)\n",
    "    for i in range(1, num_block):\n",
    "        x = block(x, out_ch, t=6, stride=1)\n",
    "    return  x\n",
    "    \n",
    "def globalFeatureExtractor(x, block_channels=[64, 96, 128], out_ch=128, t=6, num_block=(3, 3, 3), **kwargs):\n",
    "    x = _block_layer(x, linearBottlenect, block_channels[0], num_block[0], t, stride=2)\n",
    "    x = _block_layer(x, linearBottlenect, block_channels[1], num_block[1], t, stride=2)\n",
    "    x = _block_layer(x, linearBottlenect, block_channels[2], num_block[2], t, stride=1)\n",
    "    x = pyramidPooling(x, out_ch)\n",
    "    return x \n",
    "\n",
    "def featureFusionModule(high, low, out_ch, scale_factor=4, **kwargs):\n",
    "    size = np.array(high.shape[-3:-1])\n",
    "    low = tf.keras.layers.Lambda(lambda z:bilinear_interpolation(z, size))(low)\n",
    "    low = _DWConv(low, k_size=3, stride=1)\n",
    "    low = tf.keras.layers.Conv2D(out_ch,\n",
    "                               kernel_size=1,\n",
    "                               kernel_initializer='he_normal')(low)\n",
    "    low = tf.keras.layers.BatchNormalization()(low)\n",
    "    \n",
    "    high = tf.keras.layers.Conv2D(out_ch,\n",
    "                               kernel_size=1,\n",
    "                               kernel_initializer='he_normal')(high)\n",
    "    high = tf.keras.layers.BatchNormalization()(high)\n",
    "    \n",
    "    out = high + low \n",
    "    out = tf.keras.layers.Activation(\"relu\")(out)\n",
    "    return out\n",
    "    \n",
    "def classifier(x, num_classes, stride=1, train=True, **kwargs):\n",
    "    out_ch = x.shape[-1]\n",
    "    x = _DSConv(x, out_ch, stride)\n",
    "    # for boundary \n",
    "    b = tf.keras.layers.Conv2D(num_classes,\n",
    "                               kernel_size=1, \n",
    "                               kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    x = _DSConv(x, out_ch, stride)\n",
    "    x = _DSConv(x, out_ch, stride)\n",
    "    x = tf.keras.layers.Concatenate()([x, b])\n",
    "    x = _DSConv(x, out_ch, stride)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "    x = tf.keras.layers.Conv2D(num_classes,\n",
    "                               kernel_size=1, \n",
    "                               kernel_initializer='he_normal')(x)\n",
    "    \n",
    "    if train :\n",
    "        return x, b\n",
    "    return x\n",
    "\n",
    "def fastSCNN(input_shape=(256,192, 3), train=True):\n",
    "    input_ = tf.keras.layers.Input(shape=input_shape)\n",
    "    down = learningToDownsample(input_, dw_ch1=32, dw_ch2=48, out_ch=64)\n",
    "    gf = globalFeatureExtractor(down)\n",
    "    fus = featureFusionModule(down, gf, out_ch=128)\n",
    "    cls = classifier(fus, num_classes=1, train=train)\n",
    "    if train:\n",
    "        cls, boundary = cls\n",
    "        output_c = tf.keras.layers.Lambda(lambda z:bilinear_interpolation(z, input_shape[:2]))(cls)\n",
    "        output_b = tf.keras.layers.Lambda(lambda z:bilinear_interpolation(z, input_shape[:2]))(boundary)\n",
    "        output = [output_c, output_b]\n",
    "    else: \n",
    "        output = tf.keras.layers.Lambda(lambda z:bilinear_interpolation(z, input_shape[:2]))(cls)\n",
    "    return tf.keras.models.Model(input_, output)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(256,192, 3)\n",
    "model = fastSCNN(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_36 (InputLayer)           [(None, 256, 192, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_948 (Conv2D)             (None, 128, 96, 32)  896         input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1360 (Batch (None, 128, 96, 32)  128         conv2d_948[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1052 (Activation)    (None, 128, 96, 32)  0           batch_normalization_1360[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_437 (Depthwise (None, 64, 48, 32)   320         activation_1052[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1361 (Batch (None, 64, 48, 32)   128         depthwise_conv2d_437[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1053 (Activation)    (None, 64, 48, 32)   0           batch_normalization_1361[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_949 (Conv2D)             (None, 64, 48, 48)   1584        activation_1053[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1362 (Batch (None, 64, 48, 48)   192         conv2d_949[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1054 (Activation)    (None, 64, 48, 48)   0           batch_normalization_1362[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_438 (Depthwise (None, 32, 24, 48)   480         activation_1054[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1363 (Batch (None, 32, 24, 48)   192         depthwise_conv2d_438[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1055 (Activation)    (None, 32, 24, 48)   0           batch_normalization_1363[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_950 (Conv2D)             (None, 32, 24, 64)   3136        activation_1055[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1364 (Batch (None, 32, 24, 64)   256         conv2d_950[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1056 (Activation)    (None, 32, 24, 64)   0           batch_normalization_1364[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_951 (Conv2D)             (None, 32, 24, 384)  24960       activation_1056[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1365 (Batch (None, 32, 24, 384)  1536        conv2d_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1057 (Activation)    (None, 32, 24, 384)  0           batch_normalization_1365[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_439 (Depthwise (None, 16, 12, 384)  3840        activation_1057[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1366 (Batch (None, 16, 12, 384)  1536        depthwise_conv2d_439[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1058 (Activation)    (None, 16, 12, 384)  0           batch_normalization_1366[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_952 (Conv2D)             (None, 16, 12, 64)   24576       activation_1058[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1367 (Batch (None, 16, 12, 64)   256         conv2d_952[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_953 (Conv2D)             (None, 16, 12, 384)  24960       batch_normalization_1367[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1368 (Batch (None, 16, 12, 384)  1536        conv2d_953[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1059 (Activation)    (None, 16, 12, 384)  0           batch_normalization_1368[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_440 (Depthwise (None, 16, 12, 384)  3840        activation_1059[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1369 (Batch (None, 16, 12, 384)  1536        depthwise_conv2d_440[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1060 (Activation)    (None, 16, 12, 384)  0           batch_normalization_1369[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_954 (Conv2D)             (None, 16, 12, 64)   24576       activation_1060[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1370 (Batch (None, 16, 12, 64)   256         conv2d_954[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_210 (TensorFlow [(None, 16, 12, 64)] 0           batch_normalization_1367[0][0]   \n",
      "                                                                 batch_normalization_1370[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_955 (Conv2D)             (None, 16, 12, 384)  24960       tf_op_layer_add_210[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1371 (Batch (None, 16, 12, 384)  1536        conv2d_955[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1061 (Activation)    (None, 16, 12, 384)  0           batch_normalization_1371[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_441 (Depthwise (None, 16, 12, 384)  3840        activation_1061[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1372 (Batch (None, 16, 12, 384)  1536        depthwise_conv2d_441[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1062 (Activation)    (None, 16, 12, 384)  0           batch_normalization_1372[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_956 (Conv2D)             (None, 16, 12, 64)   24576       activation_1062[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1373 (Batch (None, 16, 12, 64)   256         conv2d_956[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_211 (TensorFlow [(None, 16, 12, 64)] 0           tf_op_layer_add_210[0][0]        \n",
      "                                                                 batch_normalization_1373[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_957 (Conv2D)             (None, 16, 12, 384)  24960       tf_op_layer_add_211[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1374 (Batch (None, 16, 12, 384)  1536        conv2d_957[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1063 (Activation)    (None, 16, 12, 384)  0           batch_normalization_1374[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_442 (Depthwise (None, 8, 6, 384)    3840        activation_1063[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1375 (Batch (None, 8, 6, 384)    1536        depthwise_conv2d_442[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1064 (Activation)    (None, 8, 6, 384)    0           batch_normalization_1375[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_958 (Conv2D)             (None, 8, 6, 96)     36864       activation_1064[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1376 (Batch (None, 8, 6, 96)     384         conv2d_958[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_959 (Conv2D)             (None, 8, 6, 576)    55872       batch_normalization_1376[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1377 (Batch (None, 8, 6, 576)    2304        conv2d_959[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1065 (Activation)    (None, 8, 6, 576)    0           batch_normalization_1377[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_443 (Depthwise (None, 8, 6, 576)    5760        activation_1065[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1378 (Batch (None, 8, 6, 576)    2304        depthwise_conv2d_443[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1066 (Activation)    (None, 8, 6, 576)    0           batch_normalization_1378[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_960 (Conv2D)             (None, 8, 6, 96)     55296       activation_1066[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1379 (Batch (None, 8, 6, 96)     384         conv2d_960[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_212 (TensorFlow [(None, 8, 6, 96)]   0           batch_normalization_1376[0][0]   \n",
      "                                                                 batch_normalization_1379[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_961 (Conv2D)             (None, 8, 6, 576)    55872       tf_op_layer_add_212[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1380 (Batch (None, 8, 6, 576)    2304        conv2d_961[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1067 (Activation)    (None, 8, 6, 576)    0           batch_normalization_1380[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_444 (Depthwise (None, 8, 6, 576)    5760        activation_1067[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1381 (Batch (None, 8, 6, 576)    2304        depthwise_conv2d_444[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1068 (Activation)    (None, 8, 6, 576)    0           batch_normalization_1381[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_962 (Conv2D)             (None, 8, 6, 96)     55296       activation_1068[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1382 (Batch (None, 8, 6, 96)     384         conv2d_962[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_213 (TensorFlow [(None, 8, 6, 96)]   0           tf_op_layer_add_212[0][0]        \n",
      "                                                                 batch_normalization_1382[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_963 (Conv2D)             (None, 8, 6, 576)    55872       tf_op_layer_add_213[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1383 (Batch (None, 8, 6, 576)    2304        conv2d_963[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1069 (Activation)    (None, 8, 6, 576)    0           batch_normalization_1383[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_445 (Depthwise (None, 8, 6, 576)    5760        activation_1069[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1384 (Batch (None, 8, 6, 576)    2304        depthwise_conv2d_445[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1070 (Activation)    (None, 8, 6, 576)    0           batch_normalization_1384[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_964 (Conv2D)             (None, 8, 6, 128)    73728       activation_1070[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1385 (Batch (None, 8, 6, 128)    512         conv2d_964[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_965 (Conv2D)             (None, 8, 6, 768)    99072       batch_normalization_1385[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1386 (Batch (None, 8, 6, 768)    3072        conv2d_965[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1071 (Activation)    (None, 8, 6, 768)    0           batch_normalization_1386[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_446 (Depthwise (None, 8, 6, 768)    7680        activation_1071[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1387 (Batch (None, 8, 6, 768)    3072        depthwise_conv2d_446[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1072 (Activation)    (None, 8, 6, 768)    0           batch_normalization_1387[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_966 (Conv2D)             (None, 8, 6, 128)    98304       activation_1072[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1388 (Batch (None, 8, 6, 128)    512         conv2d_966[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_214 (TensorFlow [(None, 8, 6, 128)]  0           batch_normalization_1385[0][0]   \n",
      "                                                                 batch_normalization_1388[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_967 (Conv2D)             (None, 8, 6, 768)    99072       tf_op_layer_add_214[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1389 (Batch (None, 8, 6, 768)    3072        conv2d_967[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1073 (Activation)    (None, 8, 6, 768)    0           batch_normalization_1389[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_447 (Depthwise (None, 8, 6, 768)    7680        activation_1073[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1390 (Batch (None, 8, 6, 768)    3072        depthwise_conv2d_447[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1074 (Activation)    (None, 8, 6, 768)    0           batch_normalization_1390[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_968 (Conv2D)             (None, 8, 6, 128)    98304       activation_1074[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1391 (Batch (None, 8, 6, 128)    512         conv2d_968[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_215 (TensorFlow [(None, 8, 6, 128)]  0           tf_op_layer_add_214[0][0]        \n",
      "                                                                 batch_normalization_1391[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_121 (AverageP (None, 8, 6, 128)    0           tf_op_layer_add_215[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_122 (AverageP (None, 4, 3, 128)    0           tf_op_layer_add_215[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_123 (AverageP (None, 2, 2, 128)    0           tf_op_layer_add_215[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_124 (AverageP (None, 2, 1, 128)    0           tf_op_layer_add_215[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_969 (Conv2D)             (None, 8, 6, 32)     4128        average_pooling2d_121[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_970 (Conv2D)             (None, 4, 3, 32)     4128        average_pooling2d_122[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_971 (Conv2D)             (None, 2, 2, 32)     4128        average_pooling2d_123[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_972 (Conv2D)             (None, 2, 1, 32)     4128        average_pooling2d_124[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1392 (Batch (None, 8, 6, 32)     128         conv2d_969[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1393 (Batch (None, 4, 3, 32)     128         conv2d_970[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1394 (Batch (None, 2, 2, 32)     128         conv2d_971[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1395 (Batch (None, 2, 1, 32)     128         conv2d_972[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1075 (Activation)    (None, 8, 6, 32)     0           batch_normalization_1392[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1076 (Activation)    (None, 4, 3, 32)     0           batch_normalization_1393[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1077 (Activation)    (None, 2, 2, 32)     0           batch_normalization_1394[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1078 (Activation)    (None, 2, 1, 32)     0           batch_normalization_1395[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 8, 6, 32)     0           activation_1075[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 8, 6, 32)     0           activation_1076[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 8, 6, 32)     0           activation_1077[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 8, 6, 32)     0           activation_1078[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 6, 256)    0           tf_op_layer_add_215[0][0]        \n",
      "                                                                 lambda_151[0][0]                 \n",
      "                                                                 lambda_152[0][0]                 \n",
      "                                                                 lambda_153[0][0]                 \n",
      "                                                                 lambda_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_973 (Conv2D)             (None, 8, 6, 128)    32896       concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1396 (Batch (None, 8, 6, 128)    512         conv2d_973[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1079 (Activation)    (None, 8, 6, 128)    0           batch_normalization_1396[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)             (None, 32, 24, 128)  0           activation_1079[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_448 (Depthwise (None, 32, 24, 128)  1280        lambda_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1397 (Batch (None, 32, 24, 128)  512         depthwise_conv2d_448[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1080 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1397[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_975 (Conv2D)             (None, 32, 24, 128)  8320        activation_1056[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_974 (Conv2D)             (None, 32, 24, 128)  16512       activation_1080[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1399 (Batch (None, 32, 24, 128)  512         conv2d_975[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1398 (Batch (None, 32, 24, 128)  512         conv2d_974[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_add_216 (TensorFlow [(None, 32, 24, 128) 0           batch_normalization_1399[0][0]   \n",
      "                                                                 batch_normalization_1398[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1081 (Activation)    (None, 32, 24, 128)  0           tf_op_layer_add_216[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_449 (Depthwise (None, 32, 24, 128)  1280        activation_1081[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1400 (Batch (None, 32, 24, 128)  512         depthwise_conv2d_449[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1082 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1400[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_976 (Conv2D)             (None, 32, 24, 128)  16512       activation_1082[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1401 (Batch (None, 32, 24, 128)  512         conv2d_976[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1083 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1401[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_450 (Depthwise (None, 32, 24, 128)  1280        activation_1083[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1402 (Batch (None, 32, 24, 128)  512         depthwise_conv2d_450[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1084 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1402[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_978 (Conv2D)             (None, 32, 24, 128)  16512       activation_1084[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1403 (Batch (None, 32, 24, 128)  512         conv2d_978[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1085 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1403[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_451 (Depthwise (None, 32, 24, 128)  1280        activation_1085[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1404 (Batch (None, 32, 24, 128)  512         depthwise_conv2d_451[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1086 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1404[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_979 (Conv2D)             (None, 32, 24, 128)  16512       activation_1086[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1405 (Batch (None, 32, 24, 128)  512         conv2d_979[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1087 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1405[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_977 (Conv2D)             (None, 32, 24, 1)    129         activation_1083[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 32, 24, 129)  0           activation_1087[0][0]            \n",
      "                                                                 conv2d_977[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "depthwise_conv2d_452 (Depthwise (None, 32, 24, 129)  1290        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1406 (Batch (None, 32, 24, 129)  516         depthwise_conv2d_452[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1088 (Activation)    (None, 32, 24, 129)  0           batch_normalization_1406[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_980 (Conv2D)             (None, 32, 24, 128)  16640       activation_1088[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1407 (Batch (None, 32, 24, 128)  512         conv2d_980[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_1089 (Activation)    (None, 32, 24, 128)  0           batch_normalization_1407[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 24, 128)  0           activation_1089[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_981 (Conv2D)             (None, 32, 24, 1)    129         dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 256, 192, 1)  0           conv2d_981[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)             (None, 256, 192, 1)  0           conv2d_977[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,208,032\n",
      "Trainable params: 1,183,326\n",
      "Non-trainable params: 24,706\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random(size=(1,) + input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.8 ms ± 910 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
